{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "801"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import optimize\n",
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os.path\n",
    "from os import path\n",
    "import netCDF4\n",
    "from statsmodels.tsa.stattools import acf\n",
    "import netCDF4 as nc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy import optimize\n",
    "import scipy.stats as st\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "def piecewise_linear(x, x0, y0, k1, k2):\n",
    "#   Compute optimization of fitting two connected linregs to data.\n",
    "    return np.piecewise(x, [x < x0], [lambda x:k1*x + y0-k1*x0, lambda x:k2*x + y0-k2*x0])\n",
    "\n",
    "def df_autocorr(df, lag=1, axis=0):\n",
    "#   Compute full-sample column-wise autocorrelation for a DataFrame.\n",
    "    return df.apply(lambda col: col.autocorr(lag), axis=axis)\n",
    "\"\"\"\n",
    "        optimize.curve_fit does the heavy lifting. p & e are 4-element series of results and error/uncertainties for:\n",
    "        [0] : X or soil moisture value for breakpoint\n",
    "        [1] : Y (T, flux, etc.) value for breakpoint\n",
    "        [2] : Slope on left side of breakpoint\n",
    "        [3] : slope on right side of breakpoint\n",
    "        piecewise_linear is defined above - the function to optimize over\n",
    "        Next 2 arguments are X and Y series (sorted on X) of daily data\n",
    "        p0 is an optional first guess for each of the 4 predicted parameters\n",
    "        bounds sets limits\n",
    "\"\"\"        \n",
    "pair_list=np.load('/homes/hhsu/02.InfoTheo/FluxNet/pair_list.npy')\n",
    "pair_list\n",
    "\n",
    "txtfile = '/homes/hhsu/02.InfoTheo/FluxNet/FluxNet_site_info.txt'\n",
    "id = []     # The number of the site\n",
    "name = []   # The name of the site\n",
    "lat = []    # latitude of the site\n",
    "lon = []    # lontitude of the site\n",
    "lct = []    # IGBP classification of the site\n",
    "gns = []    # Vegetation cover level of the site\n",
    "pool = []   # to mark if the site is taken by a previous detected pair: >0: available   /   0: already taken\n",
    "elv = []    # elevation of the site\n",
    "exis = []   # to mark if the site is included in FLUXNET2015 with CC by 4.9\n",
    "smdata=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pair_list=np.array([np.full((150,2),-999)]) # recording the pair by id\n",
    "diag_distance=np.array([np.full((150,2),-999)]) # Calculating the distance between all site and a given site (as the reference) for making further site spatial visualization \n",
    "newid=np.array([np.full((150,2),-999)])   # Give the pair_list a id to make further site spatial visualization \n",
    "lonnew=np.array([np.full((150,2),-999)])  # latitude of the site of sites in pair_list\n",
    "latnew=np.array([np.full((150,2),-999)])  # latitude of the site of sites in pair_list\n",
    "with open(txtfile) as f:\n",
    "    for line in f.readlines():\n",
    "        s = line.split('\\t')\n",
    "        id.append((s[0]))\n",
    "        name.append((s[1]))\n",
    "        lat.append(float(s[2])+90)\n",
    "        lon.append(float(s[3])+180)\n",
    "        lct.append((s[4]))\n",
    "        gns.append(int(s[5]))\n",
    "        pool.append(int(s[0]))\n",
    "        elv.append(float(s[6]))\n",
    "        exis.append(int(s[7]))\n",
    "np.size(lat)    \n",
    "miss_val=-9999999\n",
    "Rdry=np.array([np.full((3,267),miss_val)])\n",
    "np.size(Rdry) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir = '/homes/eseo8/python/diurnal_cycle_sm/FLUXNET/CC-BY-4.0_202002/subset/FULLSET/'\n",
    "site_list = sorted(glob.glob(dir+'*_FLUXNET2015_FULLSET_HR_*_CI_QC.csv'))\n",
    "FLX_site = [None] * len(site_list)\n",
    "\n",
    "for s,site in enumerate(site_list):\n",
    "    # print (s,site.split(\"/\")[9])\n",
    "    FLX_site[s] = site.split(\"/\")[9].split(\"_\")[1]\n",
    "del site_list\n",
    "# FLX_site\n",
    "\n",
    "dir = '/homes/eseo8/python/diurnal_cycle_sm/FLUXNET/Ameriflux/subset/FULLSET/'\n",
    "site_list = sorted(glob.glob(dir+'*_CI_QC.csv'))\n",
    "AMF_site = [None] * len(site_list)\n",
    "\n",
    "for s,site in enumerate(site_list):\n",
    "    # print (s,site.split(\"/\")[9])\n",
    "    AMF_site[s] = site.split(\"/\")[9].split(\"_\")[1]\n",
    "del site_list\n",
    "# AMF_site\n",
    "\n",
    "dir = '/homes/eseo8/python/diurnal_cycle_sm/FLUXNET/Euroflux/subset/FULLSET/'\n",
    "site_list = sorted(glob.glob(dir+'*_FLUXNET2015_FULLSET_HR_*_CI_QC.csv'))\n",
    "EUF_site = [None] * len(site_list)\n",
    "\n",
    "for s,site in enumerate(site_list):\n",
    "    # print (s,site.split(\"/\")[9])\n",
    "    EUF_site[s] = site.split(\"/\")[9].split(\"_\")[1]\n",
    "del site_list\n",
    "# EUF_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLX_AR-SLu_FLUXNET2015_FULLSET_HH_2009-2011_1-4.csv\n",
      "FLX_AR-Vir_FLUXNET2015_FULLSET_HH_2009-2012_1-4.csv\n",
      "FLX_AT-Neu_FLUXNET2015_FULLSET_HH_2002-2012_1-4.csv\n",
      "FLX_AU-ASM_FLUXNET2015_FULLSET_HH_2010-2014_2-4.csv\n",
      "FLX_AU-Ade_FLUXNET2015_FULLSET_HH_2007-2009_1-4.csv\n",
      "FLX_AU-Cpr_FLUXNET2015_FULLSET_HH_2010-2014_2-4.csv\n",
      "FLX_AU-Cum_FLUXNET2015_FULLSET_HH_2012-2014_2-4.csv\n",
      "FLX_AU-DaP_FLUXNET2015_FULLSET_HH_2007-2013_2-4.csv\n",
      "FLX_AU-DaS_FLUXNET2015_FULLSET_HH_2008-2014_2-4.csv\n",
      "FLX_AU-Dry_FLUXNET2015_FULLSET_HH_2008-2014_2-4.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-1420a5f93770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-\"\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Read file by globally seaching the file name with corresponding site name\n",
    "\n",
    "import glob\n",
    "import os\n",
    "os.chdir('/shared/land/FluxTowers/FLUXNET2015/CC-BY-4.0_202002/FULLSET/HX')\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "miss_val=-9999999.9999999\n",
    "Rdry=np.array([np.full((3,267),miss_val)])\n",
    "Rwet=np.array([np.full((3,267),miss_val)])\n",
    "SlopeSig=np.array([np.full((3,267),miss_val)])\n",
    "Tbk=np.array([np.full((3,267),miss_val)])\n",
    "SMbk=np.array([np.full((3,267),miss_val)])\n",
    "Slopedry=np.array([np.full((3,267),miss_val)])\n",
    "Slopewet=np.array([np.full((3,267),miss_val)])\n",
    "SMbk_pt=np.array([np.full((3,267),miss_val)])\n",
    "nsize=np.array([np.full((3,267),miss_val)])\n",
    "iniyear=np.array([np.full((3,267),miss_val)])\n",
    "endyear=np.array([np.full((3,267),miss_val)])\n",
    "usemonth=np.array([np.full((3,267),miss_val)])\n",
    "\n",
    "guess_dry_slope, guess_wet_slope = -50.0, -25.0\n",
    "#np.size(name)\n",
    "for listn in range(0 ,np.size(name)):\n",
    "    \n",
    "    SM_siteA=[]\n",
    "    H_siteA=[]\n",
    "    LE_siteA=[]\n",
    "    CO2_7_siteA=[]\n",
    "    C02_9_siteA=[]\n",
    "    TA_7_siteA=[]\n",
    "    TA_9_siteA=[]\n",
    "    TS_7_siteA=[]\n",
    "    TS_9_siteA=[]\n",
    "    if (listn>-1) :\n",
    "        pass\n",
    "        common_index=0\n",
    "        siteA=name[listn]\n",
    "        for file in glob.glob(\"FLX_\" + siteA + \"*\"):\n",
    "            print(file)\n",
    "        csvfileA=\"/shared/land/FluxTowers/FLUXNET2015/CC-BY-4.0_202002/FULLSET/HX/\" +file\n",
    "      \n",
    "        data_siteA = pd.read_csv(csvfileA) \n",
    "        #column_headers = list(data_siteB.columns.values)\n",
    "        #print(\"The Column Header :\", column_headers)\n",
    "\n",
    "        #Tmax, ta_0700, ta_0900 \n",
    "\n",
    "        if ('TA_F_MDS' in data_siteA.columns): \n",
    "            res = np.array(data_siteA['TIMESTAMP_START'].values.tolist())\n",
    "            time=np.array(np.full((len(res)),\"0000000000000000\")) \n",
    "\n",
    "            for i in range(0 ,int(len(res))):\n",
    "                a=str(res[i])\n",
    "                time[i]= a[0:4] + \"-\" +  a[4:6] + \"-\" + a[6:8] \n",
    "\n",
    "            data_siteA['date'] = time\n",
    "            data_siteA['date'] = pd.to_datetime(data_siteA['date'],  errors='coerce')           \n",
    "            Tmin_max_siteA=data_siteA.groupby(pd.Grouper('date'))['TA_F_MDS'].agg(['max'])\n",
    "            Tmin_max_siteA=Tmin_max_siteA['max'].replace(-9999.0, np.NaN)\n",
    "            Tmin_max_siteA=Tmin_max_siteA.to_frame()\n",
    "            \n",
    "        if ('TS_F_MDS_1' in data_siteA.columns): \n",
    "            res = np.array(data_siteA['TIMESTAMP_START'].values.tolist())\n",
    "            time=np.array(np.full((len(res)),\"0000000000000000\")) \n",
    "\n",
    "            for i in range(0 ,int(len(res))):\n",
    "                a=str(res[i])\n",
    "                time[i]= a[0:4] + \"-\" +  a[4:6] + \"-\" + a[6:8] \n",
    "\n",
    "            data_siteA['date'] = time\n",
    "            data_siteA['date'] = pd.to_datetime(data_siteA['date'],  errors='coerce')           \n",
    "            TS_max_siteA=data_siteA.groupby(pd.Grouper('date'))['TS_F_MDS_1'].agg(['max'])\n",
    "            TS_max_siteA=TS_max_siteA['max'].replace(-9999.0, np.NaN)\n",
    "            TS_max_siteA=TS_max_siteA.to_frame()\n",
    "  \n",
    "        if ('H_F_MDS' in data_siteA.columns): \n",
    "    \n",
    "            res = np.array(data_siteA['TIMESTAMP_START'].values.tolist())\n",
    "            time=np.array(np.full((len(res)),\"0000000000000000\")) \n",
    "\n",
    "            for i in range(0 ,int(len(res))):\n",
    "                a=str(res[i])\n",
    "                time[i]= a[8:10] + \"\" +  a[10:12]\n",
    "\n",
    "            data_siteA['hour'] = time\n",
    "            a=data_siteA[data_siteA[\"hour\"] == '0900']['H_F_MDS']\n",
    "            b=data_siteA[data_siteA[\"hour\"] == '1000']['H_F_MDS']\n",
    "            c=data_siteA[data_siteA[\"hour\"] == '1100']['H_F_MDS']\n",
    "            d=data_siteA[data_siteA[\"hour\"] == '1200']['H_F_MDS']\n",
    "\n",
    "            a.index=Tmin_max_siteA.index\n",
    "            b.index=Tmin_max_siteA.index\n",
    "            c.index=Tmin_max_siteA.index\n",
    "            d.index=Tmin_max_siteA.index\n",
    "            \n",
    "            SM_siteA=(a.to_frame()+b.to_frame()+c.to_frame()+d.to_frame())/4\n",
    "\n",
    "            H_siteA=SM_siteA['H_F_MDS'].replace(-9999.0, np.NaN)\n",
    "            H_siteA=H_siteA.to_frame()\n",
    "            \n",
    "        if ('SWC_F_MDS_1' in data_siteA.columns): \n",
    "    \n",
    "            res = np.array(data_siteA['TIMESTAMP_START'].values.tolist())\n",
    "            time=np.array(np.full((len(res)),\"0000000000000000\")) \n",
    "\n",
    "            for i in range(0 ,int(len(res))):\n",
    "                a=str(res[i])\n",
    "                time[i]= a[8:10] + \"\" +  a[10:12]\n",
    "\n",
    "            data_siteA['hour'] = time\n",
    "            a=data_siteA[data_siteA[\"hour\"] == '0900']['SWC_F_MDS_1']\n",
    "            a.index=Tmin_max_siteA.index\n",
    "            SM_siteA=a.to_frame()\n",
    "\n",
    "            SM_siteA=SM_siteA['SWC_F_MDS_1'].replace(-9999.0, np.NaN)\n",
    "            SM_siteA=SM_siteA.to_frame()\n",
    "        \n",
    "            Tmin_max_siteA=Tmin_max_siteA.dropna(subset=['max'])\n",
    "            SM_siteA=SM_siteA.dropna(subset=['SWC_F_MDS_1'])\n",
    "            common_index = set(Tmin_max_siteA.index).intersection(SM_siteA.index).intersection(TS_max_siteA.index)\n",
    "            if len(common_index) > 0:\n",
    "                try:\n",
    "                    Tmin_max_siteA = Tmin_max_siteA.loc[common_index].copy()\n",
    "                    Tmin_max_siteA = Tmin_max_siteA.sort_values(by='date')\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "\n",
    "                    TS_max_siteA = TS_max_siteA.loc[common_index].copy()\n",
    "                    TS_max_siteA = TS_max_siteA.sort_values(by='date')\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "\n",
    "                    SM_siteA = SM_siteA.loc[common_index].copy()\n",
    "                    SM_siteA = SM_siteA.sort_values(by='date')\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "\n",
    "                    H_siteA = H_siteA.loc[common_index].copy()\n",
    "                    H_siteA = H_siteA.sort_values(by='date')\n",
    "                except:\n",
    "                    pass\n",
    "            try:\n",
    "                Tmin_max_siteA_ano = Tmin_max_siteA.groupby(Tmin_max_siteA.index.month).transform(lambda g: g - g.mean())\n",
    "                Tmin_max_siteA_cli = Tmin_max_siteA.groupby(Tmin_max_siteA.index.month).transform(lambda g:  g.mean())\n",
    "                a=Tmin_max_siteA_cli.groupby(Tmin_max_siteA_cli.index.month)['max'].agg(['max']).to_numpy()\n",
    "                x = np.where(a == a.max())[0]+1\n",
    "                um=[x[0]-1,x[0],x[0]+1]\n",
    "                if x[0]>11:\n",
    "                    um=[11,12,1]\n",
    "                if x[0]<2:    \n",
    "                    um=[12,1,2]\n",
    "                for i in range(0,3):\n",
    "                    a = Tmin_max_siteA.index.month==um[i]    \n",
    "\n",
    "                    guess_dry_slope, guess_wet_slope = -50.0, -25.0\n",
    "\n",
    "                    lacc=SM_siteA[a].groupby(SM_siteA[a].index.year)['SWC_F_MDS_1'].apply(lambda x: x.autocorr(lag=1))\n",
    "                    tau = -1/np.log(np.sqrt(np.sum(lacc*np.abs(lacc))/np.size(lacc)))\n",
    "                    dof=np.rint(float(len(SM_siteA[a]['SWC_F_MDS_1'])) / (tau + 1))\n",
    "\n",
    "                    sm_sort=SM_siteA[a]['SWC_F_MDS_1'].to_numpy()\n",
    "                    tx_sort=H_siteA[a]['H_F_MDS'].to_numpy()\n",
    "\n",
    "                    p , e = optimize.curve_fit(piecewise_linear, sm_sort, tx_sort, p0=[np.median(sm_sort),np.median(tx_sort),guess_dry_slope,guess_wet_slope], bounds=([np.min(sm_sort),np.min(tx_sort),-np.inf,-np.inf], [np.max(sm_sort),np.max(tx_sort),np.inf,np.inf]))\n",
    "                    wet_pts = sum(i > p[0] for i in sm_sort) \n",
    "                    dry_pts = sum(i <= p[0] for i in sm_sort) \n",
    "                    perr = np.sqrt(np.diag(e))\n",
    "                    vest = math.sqrt((tau+1)*(perr[2]*perr[2]/dry_pts+perr[3]*perr[3]/wet_pts)) # Adjust DOFs by tau, calculate z & p values for signif slope change\n",
    "                    z = abs(p[2]-p[3])/vest\n",
    "                    pval = st.norm.sf(abs(z))            \n",
    "                    dry_corr, dry_corp = st.pearsonr(sm_sort[:dry_pts],tx_sort[:dry_pts])\n",
    "                    wet_corr, wet_corp = st.pearsonr(sm_sort[-wet_pts:],tx_sort[-wet_pts:])\n",
    "\n",
    "\n",
    "\n",
    "                    Rdry[0,i,listn]=dry_corr\n",
    "                    Rwet[0,i,listn]=wet_corr\n",
    "                    SlopeSig[0,i,listn]=pval\n",
    "                    SMbk[0,i,listn]=p[0]\n",
    "                    Tbk[0,i,listn]=p[1]\n",
    "                    Slopedry[0,i,listn]=p[2]\n",
    "                    Slopewet[0,i,listn]=p[3]\n",
    "                    SMbk_pt[0,i,listn]=np.percentile(sm_sort,p[0]) \n",
    "                    nsize[0,i,listn]=np.size(sm_sort)\n",
    "                    iniyear[0,i,listn]=SM_siteA[a].index.year[1]\n",
    "                    endyear[0,i,listn]=SM_siteA[a].index.year[-1]\n",
    "                    usemonth[0,i,listn]=um[i]  \n",
    "\n",
    "            except:\n",
    "                    pass\n",
    "\n",
    "np.save('/homes/hhsu/02.InfoTheo/FluxNet/bl_sm_h.npy', np.array([Rdry, Rwet, SlopeSig, Tbk, SMbk, Slopedry, Slopewet, SMbk_pt, usemonth, nsize, iniyear, endyear]))\n",
    "#plt.savefig('/homes/hhsu/02.InfoTheo/FluxNet/Map_diag_SM_H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_AR-TF1_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_BR-Npw_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-ARB_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-ARF_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-Ca1_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-Ca2_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-Ca3_BASE_HH_4-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-Cbo_BASE_HH_3-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-DBB_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-ER1_BASE_HH_3-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-Let_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-MA2_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-MA3_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-Ojp_BASE_HH_2-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-Qc2_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-Qcu_BASE_HH_1-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-SCC_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-SJ1_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-SJ2_BASE_HH_2-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-SJ3_BASE_HH_2-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CA-WP1_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_CR-Lse_BASE_HH_2-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_MX-Aog_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_MX-EMg_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_MX-Lpa_BASE_HH_1-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_MX-Tes_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-ADR_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-ALQ_BASE_HH_5-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Aud_BASE_HH_4-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-BRG_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-BZB_BASE_HH_4-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-BZF_BASE_HH_4-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Bar_BASE_HH_5-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Bi1_BASE_HH_8-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Bi2_BASE_HH_9-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Bkg_BASE_HH_4-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Blk_BASE_HH_2-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Bn1_BASE_HH_1-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Bn2_BASE_HH_1-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Bn3_BASE_HH_1-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Bo1_BASE_HH_2-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Br1_BASE_HH_1-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Br3_BASE_HH_1-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-CMW_BASE_HH_2-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-CPk_BASE_HH_2-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-CZ2_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-CZ3_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-CaV_BASE_HH_2-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Ced_BASE_HH_7-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-ChR_BASE_HH_2-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Ctn_BASE_HH_2-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Cwt_BASE_HR_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-DPW_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Dix_BASE_HH_2-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Dk1_BASE_HH_4-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Dk2_BASE_HH_4-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Dk3_BASE_HH_4-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-EML_BASE_HH_3-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-FPe_BASE_HH_2-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-FR2_BASE_HH_2-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-FR3_BASE_HH_1-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Fcr_BASE_HH_2-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Fmf_BASE_HH_6-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Fuf_BASE_HH_6-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Fwf_BASE_HH_8-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-GMF_BASE_HH_2-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Ha2_BASE_HH_8-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Ho1_BASE_HH_6-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Ho2_BASE_HH_3-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-IB1_BASE_HH_8-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-ICs_BASE_HH_7-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-ICt_BASE_HH_5-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Jo1_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Jo2_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-KFS_BASE_HH_7-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-KL1_BASE_HH_3-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-KL2_BASE_HH_4-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-KL3_BASE_HH_4-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-KLS_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-KM1_BASE_HH_4-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-KM2_BASE_HH_4-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-KM3_BASE_HH_3-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-KM4_BASE_HH_5-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-KUT_BASE_HH_1-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Kon_BASE_HH_5-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-LL1_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-LL2_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-LL3_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-LS1_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-LS2_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-MOz_BASE_HH_8-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-MRf_BASE_HH_4-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Mpj_BASE_HH_20-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-MtB_BASE_HH_4-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-NC1_BASE_HH_3-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-NC2_BASE_HH_7-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-NC3_BASE_HH_4-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-NC4_BASE_HH_5-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-ONA_BASE_HH_3-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-PHM_BASE_HH_2-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Pon_BASE_HH_2-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-RC1_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-RC2_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-RC3_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-RC4_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-RC5_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Rls_BASE_HH_3-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Rms_BASE_HH_3-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Ro1_BASE_HH_5-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Ro3_BASE_HH_4-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Ro4_BASE_HH_18-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Ro5_BASE_HH_18-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Ro6_BASE_HH_18-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Rpf_BASE_HH_7-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Rwf_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Rws_BASE_HH_3-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-SCd_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-SCf_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-SCg_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-SCs_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-SCw_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-SO2_BASE_HH_1-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-SO3_BASE_HH_1-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-SO4_BASE_HH_1-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-SP2_BASE_HH_3-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-SP3_BASE_HH_3-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-SRS_BASE_HH_2-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-SdH_BASE_HH_1-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Seg_BASE_HH_20-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Ses_BASE_HH_20-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Shd_BASE_HH_2-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Skr_BASE_HH_1-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Slt_BASE_HH_5-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Snd_BASE_HH_2-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Sne_BASE_HH_7-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Srr_BASE_HH_1-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Uaf_BASE_HH_8-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Vcm_BASE_HH_22-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Vcp_BASE_HH_19-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Vcs_BASE_HH_8-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-WBW_BASE_HH_2-1.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Wjs_BASE_HH_19-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Wlr_BASE_HH_4-5.csv\n",
      "/shared/land/FluxTowers/Ameriflux/HX/AMF_US-Wrc_BASE_HH_8-1.csv\n"
     ]
    }
   ],
   "source": [
    "#Read file by globally seaching the file name with corresponding site name\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "miss_val=-9999999.9999999\n",
    "Rdry=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "Rwet=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "SlopeSig=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "Tbk=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "SMbk=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "Slopedry=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "Slopewet=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "SMbk_pt=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "nsize=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "iniyear=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "endyear=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "usemonth=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "flagg=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "\n",
    "guess_dry_slope, guess_wet_slope = -50.0, -25.0\n",
    "#np.size(name)\n",
    "for listn in range(0,np.size(AMF_site)):\n",
    "    \n",
    "    SM_siteA=[]\n",
    "    H_siteA=[]\n",
    "    LE_siteA=[]\n",
    "    CO2_7_siteA=[]\n",
    "    C02_9_siteA=[]\n",
    "    TA_7_siteA=[]\n",
    "    TA_9_siteA=[]\n",
    "    TS_7_siteA=[]\n",
    "    TS_9_siteA=[]\n",
    "    if (listn>-1) :\n",
    "        pass\n",
    "        common_index=0\n",
    "        siteA=AMF_site[listn]\n",
    "        aaa=len(glob.glob(\"/shared/land/FluxTowers/FLUXNET2015/CC-BY-4.0_202002/FULLSET/HX/FLX_\" + siteA + \"*\"))\n",
    "        bbb=len(glob.glob(\"/shared/land/FluxTowers/Ameriflux/HX/AMF_\" + siteA + \"*\"))\n",
    "        \n",
    "        if aaa<1 and bbb>0:\n",
    "            flagg[0,0,listn]=1\n",
    "            \n",
    "            for file in glob.glob(\"/shared/land/FluxTowers/Ameriflux/HX/AMF_\" + siteA + \"*\"):\n",
    "                print(file)\n",
    "            csvfileA=file\n",
    "            data_siteA = pd.read_csv(csvfileA,skiprows=2)  \n",
    "            #column_headers = list(data_siteB.columns.values)\n",
    "            #print(\"The Column Header :\", column_headers)\n",
    "\n",
    "            #Tmax, ta_0700, ta_0900 \n",
    "\n",
    "            if ('TA' in data_siteA.columns): \n",
    "                res = np.array(data_siteA['TIMESTAMP_START'].values.tolist())\n",
    "                time=np.array(np.full((len(res)),\"0000000000000000\")) \n",
    "\n",
    "                for i in range(0 ,int(len(res))):\n",
    "                    a=str(res[i])\n",
    "                    time[i]= a[0:4] + \"-\" +  a[4:6] + \"-\" + a[6:8] \n",
    "                \n",
    "                data_siteA['date'] = time\n",
    "                data_siteA['date'] = pd.to_datetime(data_siteA['date'],  errors='coerce')           \n",
    "                Tmin_max_siteA=data_siteA.groupby(pd.Grouper('date'))['TA'].agg(['max'])\n",
    "                dddd=data_siteA.groupby(pd.Grouper('date'))['TA'].agg(['max']).index\n",
    "                Tmin_max_siteA=Tmin_max_siteA['max'].replace(-9999.0, np.NaN)\n",
    "                Tmin_max_siteA=Tmin_max_siteA.to_frame()\n",
    "                try:\n",
    "                    if ('TS_1' in data_siteA.columns): \n",
    "                        res = np.array(data_siteA['TIMESTAMP_START'].values.tolist())\n",
    "                        time=np.array(np.full((len(res)),\"0000000000000000\")) \n",
    "\n",
    "                        for i in range(0 ,int(len(res))):\n",
    "                            a=str(res[i])\n",
    "                            time[i]= a[0:4] + \"-\" +  a[4:6] + \"-\" + a[6:8] \n",
    "\n",
    "                        data_siteA['date'] = time\n",
    "                        data_siteA['date'] = pd.to_datetime(data_siteA['date'],  errors='coerce')           \n",
    "                        TS_max_siteA=data_siteA.groupby(pd.Grouper('date'))['TS_1'].agg(['max'])\n",
    "                        TS_max_siteA=TS_max_siteA['max'].replace(-9999.0, np.NaN)\n",
    "                        TS_max_siteA=TS_max_siteA.to_frame()\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    if ('H' in data_siteA.columns): \n",
    "\n",
    "                        res = np.array(data_siteA['TIMESTAMP_START'].values.tolist())\n",
    "                        time=np.array(np.full((len(res)),\"0000000000000000\")) \n",
    "\n",
    "                        for i in range(0 ,int(len(res))):\n",
    "                            a=str(res[i])\n",
    "                            time[i]= a[8:10] + \"\" +  a[10:12]\n",
    "\n",
    "                        data_siteA['hour'] = time\n",
    "                        a=data_siteA[data_siteA[\"hour\"] == '0900']['H']\n",
    "                        b=data_siteA[data_siteA[\"hour\"] == '1000']['H']\n",
    "                        c=data_siteA[data_siteA[\"hour\"] == '1100']['H']\n",
    "                        d=data_siteA[data_siteA[\"hour\"] == '1200']['H']\n",
    "\n",
    "                        a.index=dddd\n",
    "                        b.index=dddd\n",
    "                        c.index=dddd\n",
    "                        d.index=dddd\n",
    "\n",
    "                        SM_siteA=(a.to_frame()+b.to_frame()+c.to_frame()+d.to_frame())/4\n",
    "\n",
    "                        H_siteA=SM_siteA['H'].replace(-9999.0, np.NaN)\n",
    "                        H_siteA=H_siteA.to_frame()\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    if ('SWC_1' in data_siteA.columns): \n",
    "\n",
    "                        res = np.array(data_siteA['TIMESTAMP_START'].values.tolist())\n",
    "                        time=np.array(np.full((len(res)),\"0000000000000000\")) \n",
    "\n",
    "                        for i in range(0 ,int(len(res))):\n",
    "                            a=str(res[i])\n",
    "                            time[i]= a[8:10] + \"\" +  a[10:12]\n",
    "\n",
    "                        data_siteA['hour'] = time\n",
    "                        a=data_siteA[data_siteA[\"hour\"] == '0900']['SWC_1']\n",
    "                        a.index=Tmin_max_siteA.index\n",
    "                        SM_siteA=a.to_frame()\n",
    "\n",
    "                        SM_siteA=SM_siteA['SWC_1'].replace(-9999.0, np.NaN)\n",
    "                        SM_siteA=SM_siteA.to_frame()\n",
    "                        Tmin_max_siteA=Tmin_max_siteA.dropna(subset=['max'])\n",
    "                        TS_max_siteA=TS_max_siteA.dropna(subset=['max'])\n",
    "                        SM_siteA=SM_siteA.dropna(subset=['SWC_1'])\n",
    "                        H_siteA=H_siteA.dropna(subset=['H'])\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    common_index = set(Tmin_max_siteA.index).intersection(SM_siteA.index).intersection(TS_max_siteA.index).intersection(H_siteA.index)\n",
    "                    if len(common_index) > 0:\n",
    "                        try:\n",
    "                            Tmin_max_siteA = Tmin_max_siteA.loc[common_index].copy()\n",
    "                            Tmin_max_siteA = Tmin_max_siteA.sort_values(by='date')\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "\n",
    "                            TS_max_siteA = TS_max_siteA.loc[common_index].copy()\n",
    "                            TS_max_siteA = TS_max_siteA.sort_values(by='date')\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "\n",
    "                            SM_siteA = SM_siteA.loc[common_index].copy()\n",
    "                            SM_siteA = SM_siteA.sort_values(by='date')\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "\n",
    "                            H_siteA = H_siteA.loc[common_index].copy()\n",
    "                            H_siteA = H_siteA.sort_values(by='date')\n",
    "                        except:\n",
    "                            pass\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    Tmin_max_siteA_ano = Tmin_max_siteA.groupby(Tmin_max_siteA.index.month).transform(lambda g: g - g.mean())\n",
    "                    Tmin_max_siteA_cli = Tmin_max_siteA.groupby(Tmin_max_siteA.index.month).transform(lambda g:  g.mean())\n",
    "                    a=Tmin_max_siteA_cli.groupby(Tmin_max_siteA_cli.index.month)['max'].agg(['max']).to_numpy()\n",
    "                    x = np.where(a == a.max())[0]+1\n",
    "                    um=[x[0]-1,x[0],x[0]+1]\n",
    "                    if x[0]>11:\n",
    "                        um=[11,12,1]\n",
    "                    if x[0]<2:    \n",
    "                        um=[12,1,2]\n",
    "                    for i in range(0,3):\n",
    "                        a = Tmin_max_siteA.index.month==um[i]    \n",
    "\n",
    "                        guess_dry_slope, guess_wet_slope = -50.0, -25.0\n",
    "\n",
    "                        lacc=SM_siteA[a].groupby(SM_siteA[a].index.year)['SWC_1'].apply(lambda x: x.autocorr(lag=1))\n",
    "                        tau = -1/np.log(np.sqrt(np.sum(lacc*np.abs(lacc))/np.size(lacc)))\n",
    "                        dof=np.rint(float(len(SM_siteA[a]['SWC_1'])) / (tau + 1))\n",
    "\n",
    "                        sm_sort=SM_siteA[a]['SWC_1'].to_numpy()\n",
    "                        tx_sort=H_siteA[a]['H'].to_numpy()\n",
    "\n",
    "                        p , e = optimize.curve_fit(piecewise_linear, sm_sort, tx_sort, p0=[np.median(sm_sort),np.median(tx_sort),guess_dry_slope,guess_wet_slope], bounds=([np.min(sm_sort),np.min(tx_sort),-np.inf,-np.inf], [np.max(sm_sort),np.max(tx_sort),np.inf,np.inf]))\n",
    "                        wet_pts = sum(i > p[0] for i in sm_sort) \n",
    "                        dry_pts = sum(i <= p[0] for i in sm_sort) \n",
    "                        perr = np.sqrt(np.diag(e))\n",
    "                        vest = math.sqrt((tau+1)*(perr[2]*perr[2]/dry_pts+perr[3]*perr[3]/wet_pts)) # Adjust DOFs by tau, calculate z & p values for signif slope change\n",
    "                        z = abs(p[2]-p[3])/vest\n",
    "                        pval = st.norm.sf(abs(z))            \n",
    "                        dry_corr, dry_corp = st.pearsonr(sm_sort[:dry_pts],tx_sort[:dry_pts])\n",
    "                        wet_corr, wet_corp = st.pearsonr(sm_sort[-wet_pts:],tx_sort[-wet_pts:])\n",
    "\n",
    "\n",
    "\n",
    "                        Rdry[0,i,listn]=dry_corr\n",
    "                        Rwet[0,i,listn]=wet_corr\n",
    "                        SlopeSig[0,i,listn]=pval\n",
    "                        SMbk[0,i,listn]=p[0]\n",
    "                        Tbk[0,i,listn]=p[1]\n",
    "                        Slopedry[0,i,listn]=p[2]\n",
    "                        Slopewet[0,i,listn]=p[3]\n",
    "                        SMbk_pt[0,i,listn]=np.percentile(sm_sort,p[0]) \n",
    "                        nsize[0,i,listn]=np.size(sm_sort)\n",
    "                        iniyear[0,i,listn]=SM_siteA[a].index.year[1]\n",
    "                        endyear[0,i,listn]=SM_siteA[a].index.year[-1]\n",
    "                        usemonth[0,i,listn]=um[i] \n",
    "\n",
    "                except:\n",
    "                        pass\n",
    "             \n",
    "np.save('/homes/hhsu/02.InfoTheo/FluxNet/bl_sm_h_Amer.npy', np.array([Rdry, Rwet, SlopeSig, Tbk, SMbk, Slopedry, Slopewet,SMbk_pt, usemonth, nsize, iniyear, endyear, flagg]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_CH-Aws_FLUXNET2015_FULLSET_HH_2010-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_CZ-Lnz_FLUXNET2015_FULLSET_HH_2015-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_CZ-RAJ_FLUXNET2015_FULLSET_HH_2012-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_CZ-Stn_FLUXNET2015_FULLSET_HH_2010-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_DE-HoH_FLUXNET2015_FULLSET_HH_2015-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_DE-Hte_FLUXNET2015_FULLSET_HH_2009-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_DE-Hzd_FLUXNET2015_FULLSET_HH_2010-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_DE-RuW_FLUXNET2015_FULLSET_HH_2010-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_ES-Abr_FLUXNET2015_FULLSET_HH_2015-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_ES-LM1_FLUXNET2015_FULLSET_HH_2014-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_ES-LM2_FLUXNET2015_FULLSET_HH_2014-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_FI-Sii_FLUXNET2015_FULLSET_HH_2016-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_FI-Var_FLUXNET2015_FULLSET_HH_2016-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_FR-Bil_FLUXNET2015_FULLSET_HH_2014-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_FR-EM2_FLUXNET2015_FULLSET_HH_2017-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_FR-Hes_FLUXNET2015_FULLSET_HH_2014-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_IT-Lsn_FLUXNET2015_FULLSET_HH_2016-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_RU-Fy2_FLUXNET2015_FULLSET_HH_2015-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_SE-Deg_FLUXNET2015_FULLSET_HH_2001-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_SE-Htm_FLUXNET2015_FULLSET_HH_2015-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_SE-Lnn_FLUXNET2015_FULLSET_HH_2014-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_SE-Nor_FLUXNET2015_FULLSET_HH_2014-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_SE-Ros_FLUXNET2015_FULLSET_HH_2014-2018_beta-3.csv\n",
      "/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_SE-Svb_FLUXNET2015_FULLSET_HH_2014-2018_beta-3.csv\n"
     ]
    }
   ],
   "source": [
    "#Read file by globally seaching the file name with corresponding site name\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "miss_val=-9999999.9999999\n",
    "Rdry=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "Rwet=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "SlopeSig=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "Tbk=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "SMbk=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "Slopedry=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "Slopewet=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "SMbk_pt=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "nsize=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "iniyear=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "endyear=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "usemonth=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "flagg=np.array([np.full((3,np.size(AMF_site)),miss_val)])\n",
    "\n",
    "guess_dry_slope, guess_wet_slope = -50.0, -25.0\n",
    "#np.size(name)\n",
    "for listn in range(0 ,np.size(EUF_site)):\n",
    "    \n",
    "    SM_siteA=[]\n",
    "    H_siteA=[]\n",
    "    LE_siteA=[]\n",
    "    CO2_7_siteA=[]\n",
    "    C02_9_siteA=[]\n",
    "    TA_7_siteA=[]\n",
    "    TA_9_siteA=[]\n",
    "    TS_7_siteA=[]\n",
    "    TS_9_siteA=[]\n",
    "    a_siteA=[]\n",
    "    if (listn>-1) :\n",
    "        pass\n",
    "        common_index=0\n",
    "        siteA=EUF_site[listn]\n",
    "        aaa=len(glob.glob(\"/shared/land/FluxTowers/FLUXNET2015/CC-BY-4.0_202002/FULLSET/HX/FLX_\" + siteA + \"*\"))\n",
    "        bbb=len(glob.glob(\"/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_\" + siteA + \"_FLUXNET2015_FULLSET_HH*\"))\n",
    "        \n",
    "        if aaa<1 and bbb>0:\n",
    "            flagg[0,0,listn]=1\n",
    "            for file in glob.glob(\"/shared/land/FluxTowers/FLUXNET2015/Europe_2018/FULLSET/FLX_\" + siteA + \"_FLUXNET2015_FULLSET_HH*\"):\n",
    "                print(file)\n",
    "            csvfileA=file\n",
    "            data_siteA = pd.read_csv(csvfileA)  \n",
    "            #column_headers = list(data_siteB.columns.values)\n",
    "            #print(\"The Column Header :\", column_headers)\n",
    "\n",
    "            #Tmax, ta_0700, ta_0900 \n",
    "\n",
    "            if ('TA_F_MDS' in data_siteA.columns): \n",
    "                res = np.array(data_siteA['TIMESTAMP_START'].values.tolist())\n",
    "                time=np.array(np.full((len(res)),\"0000000000000000\")) \n",
    "\n",
    "                for i in range(0 ,int(len(res))):\n",
    "                    a=str(res[i])\n",
    "                    time[i]= a[0:4] + \"-\" +  a[4:6] + \"-\" + a[6:8] \n",
    "\n",
    "                data_siteA['date'] = time\n",
    "                data_siteA['date'] = pd.to_datetime(data_siteA['date'],  errors='coerce')           \n",
    "                Tmin_max_siteA=data_siteA.groupby(pd.Grouper('date'))['TA_F_MDS'].agg(['max'])\n",
    "                Tmin_max_siteA=Tmin_max_siteA['max'].replace(-9999.0, np.NaN)\n",
    "                Tmin_max_siteA=Tmin_max_siteA.to_frame()\n",
    "\n",
    "            if ('TS_F_MDS_1' in data_siteA.columns): \n",
    "                res = np.array(data_siteA['TIMESTAMP_START'].values.tolist())\n",
    "                time=np.array(np.full((len(res)),\"0000000000000000\")) \n",
    "\n",
    "                for i in range(0 ,int(len(res))):\n",
    "                    a=str(res[i])\n",
    "                    time[i]= a[0:4] + \"-\" +  a[4:6] + \"-\" + a[6:8] \n",
    "\n",
    "                data_siteA['date'] = time\n",
    "                data_siteA['date'] = pd.to_datetime(data_siteA['date'],  errors='coerce')           \n",
    "                TS_max_siteA=data_siteA.groupby(pd.Grouper('date'))['TS_F_MDS_1'].agg(['max'])\n",
    "                TS_max_siteA=TS_max_siteA['max'].replace(-9999.0, np.NaN)\n",
    "                TS_max_siteA=TS_max_siteA.to_frame()\n",
    "\n",
    "            if ('H_F_MDS' in data_siteA.columns): \n",
    "\n",
    "                res = np.array(data_siteA['TIMESTAMP_START'].values.tolist())\n",
    "                time=np.array(np.full((len(res)),\"0000000000000000\")) \n",
    "\n",
    "                for i in range(0 ,int(len(res))):\n",
    "                    a=str(res[i])\n",
    "                    time[i]= a[8:10] + \"\" +  a[10:12]\n",
    "\n",
    "                data_siteA['hour'] = time\n",
    "                a=data_siteA[data_siteA[\"hour\"] == '0900']['H_F_MDS']\n",
    "                b=data_siteA[data_siteA[\"hour\"] == '1000']['H_F_MDS']\n",
    "                c=data_siteA[data_siteA[\"hour\"] == '1100']['H_F_MDS']\n",
    "                d=data_siteA[data_siteA[\"hour\"] == '1200']['H_F_MDS']\n",
    "\n",
    "                a.index=Tmin_max_siteA.index\n",
    "                b.index=Tmin_max_siteA.index\n",
    "                c.index=Tmin_max_siteA.index\n",
    "                d.index=Tmin_max_siteA.index\n",
    "\n",
    "                a_siteA=(a.to_frame()+b.to_frame()+c.to_frame()+d.to_frame())/4\n",
    "\n",
    "                H_siteA=a_siteA['H_F_MDS'].replace(-9999.0, np.NaN)\n",
    "                H_siteA=H_siteA.to_frame()\n",
    "            \n",
    "            if ('SWC_F_MDS_1' in data_siteA.columns): \n",
    "\n",
    "                res = np.array(data_siteA['TIMESTAMP_START'].values.tolist())\n",
    "                time=np.array(np.full((len(res)),\"0000000000000000\")) \n",
    "\n",
    "                for i in range(0 ,int(len(res))):\n",
    "                    a=str(res[i])\n",
    "                    time[i]= a[8:10] + \"\" +  a[10:12]\n",
    "\n",
    "                data_siteA['hour'] = time\n",
    "                a=data_siteA[data_siteA[\"hour\"] == '0900']['SWC_F_MDS_1']\n",
    "                a.index=Tmin_max_siteA.index\n",
    "                SM_siteA=a.to_frame()\n",
    "\n",
    "                SM_siteA=SM_siteA['SWC_F_MDS_1'].replace(-9999.0, np.NaN)\n",
    "                SM_siteA=SM_siteA.to_frame()\n",
    "\n",
    "                Tmin_max_siteA=Tmin_max_siteA.dropna(subset=['max'])\n",
    "                TS_max_siteA=TS_max_siteA.dropna(subset=['max'])\n",
    "                SM_siteA=SM_siteA.dropna(subset=['SWC_F_MDS_1'])\n",
    "                H_siteA=H_siteA.dropna(subset=['H_F_MDS'])\n",
    "              \n",
    "            try:\n",
    "                common_index = set(Tmin_max_siteA.index).intersection(SM_siteA.index).intersection(TS_max_siteA.index).intersection(H_siteA.index)\n",
    "                if len(common_index) > 0:\n",
    "                    try:\n",
    "                        Tmin_max_siteA = Tmin_max_siteA.loc[common_index].copy()\n",
    "                        Tmin_max_siteA = Tmin_max_siteA.sort_values(by='date')\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "\n",
    "                        TS_max_siteA = TS_max_siteA.loc[common_index].copy()\n",
    "                        TS_max_siteA = TS_max_siteA.sort_values(by='date')\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "\n",
    "                        SM_siteA = SM_siteA.loc[common_index].copy()\n",
    "                        SM_siteA = SM_siteA.sort_values(by='date')\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "\n",
    "                        H_siteA = H_siteA.loc[common_index].copy()\n",
    "                        H_siteA = H_siteA.sort_values(by='date')\n",
    "                    except:\n",
    "                        pass\n",
    "            except:\n",
    "                 pass\n",
    "            try:\n",
    "                Tmin_max_siteA_ano = Tmin_max_siteA.groupby(Tmin_max_siteA.index.month).transform(lambda g: g - g.mean())\n",
    "                Tmin_max_siteA_cli = Tmin_max_siteA.groupby(Tmin_max_siteA.index.month).transform(lambda g:  g.mean())\n",
    "                a=Tmin_max_siteA_cli.groupby(Tmin_max_siteA_cli.index.month)['max'].agg(['max']).to_numpy()\n",
    "                x = np.where(a == a.max())[0]+1\n",
    "                um=[x[0]-1,x[0],x[0]+1]\n",
    "                if x[0]>11:\n",
    "                    um=[11,12,1]\n",
    "                if x[0]<2:    \n",
    "                    um=[12,1,2]\n",
    "                for i in range(0,3):\n",
    "                    a = Tmin_max_siteA.index.month==um[i]    \n",
    "\n",
    "                    guess_dry_slope, guess_wet_slope = -50.0, -25.0\n",
    "\n",
    "                    lacc=SM_siteA[a].groupby(SM_siteA[a].index.year)['SWC_F_MDS_1'].apply(lambda x: x.autocorr(lag=1))\n",
    "                    tau = -1/np.log(np.sqrt(np.sum(lacc*np.abs(lacc))/np.size(lacc)))\n",
    "                    dof=np.rint(float(len(SM_siteA[a]['SWC_F_MDS_1'])) / (tau + 1))\n",
    "\n",
    "                    sm_sort=SM_siteA[a]['SWC_F_MDS_1'].to_numpy()\n",
    "                    tx_sort=H_siteA[a]['H_F_MDS'].to_numpy()\n",
    "\n",
    "                    p , e = optimize.curve_fit(piecewise_linear, sm_sort, tx_sort, p0=[np.median(sm_sort),np.median(tx_sort),guess_dry_slope,guess_wet_slope], bounds=([np.min(sm_sort),np.min(tx_sort),-np.inf,-np.inf], [np.max(sm_sort),np.max(tx_sort),np.inf,np.inf]))\n",
    "                    wet_pts = sum(i > p[0] for i in sm_sort) \n",
    "                    dry_pts = sum(i <= p[0] for i in sm_sort) \n",
    "                    perr = np.sqrt(np.diag(e))\n",
    "                    vest = math.sqrt((tau+1)*(perr[2]*perr[2]/dry_pts+perr[3]*perr[3]/wet_pts)) # Adjust DOFs by tau, calculate z & p values for signif slope change\n",
    "                    z = abs(p[2]-p[3])/vest\n",
    "                    pval = st.norm.sf(abs(z))            \n",
    "                    dry_corr, dry_corp = st.pearsonr(sm_sort[:dry_pts],tx_sort[:dry_pts])\n",
    "                    wet_corr, wet_corp = st.pearsonr(sm_sort[-wet_pts:],tx_sort[-wet_pts:])\n",
    "\n",
    "\n",
    "\n",
    "                    Rdry[0,i,listn]=dry_corr\n",
    "                    Rwet[0,i,listn]=wet_corr\n",
    "                    SlopeSig[0,i,listn]=pval\n",
    "                    SMbk[0,i,listn]=p[0]\n",
    "                    Tbk[0,i,listn]=p[1]\n",
    "                    Slopedry[0,i,listn]=p[2]\n",
    "                    Slopewet[0,i,listn]=p[3]\n",
    "                    SMbk_pt[0,i,listn]=np.percentile(sm_sort,p[0]) \n",
    "                    nsize[0,i,listn]=np.size(sm_sort)\n",
    "                    iniyear[0,i,listn]=SM_siteA[a].index.year[1]\n",
    "                    endyear[0,i,listn]=SM_siteA[a].index.year[-1]\n",
    "                    usemonth[0,i,listn]=um[i] \n",
    "\n",
    "            except:\n",
    "                    pass\n",
    "np.save('/homes/hhsu/02.InfoTheo/FluxNet/bl_sm_h_Euf.npy', np.array([Rdry, Rwet, SlopeSig, Tbk, SMbk, Slopedry, Slopewet,SMbk_pt, usemonth, nsize, iniyear, endyear, flagg]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -3.41794165e-01, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -3.09283817e-01, -2.48886554e-01,\n",
       "         -1.86870715e-02, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -2.88731068e-02, -1.00000000e+07, -8.64839693e-01,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -2.00647980e-01, -1.00000000e+07,\n",
       "         -1.00000000e+07,  2.99318801e-01, -5.44331035e-01,\n",
       "         -5.84131521e-01, -1.00000000e+07, -1.00000000e+07,\n",
       "          1.30537980e-01, -6.31892711e-02, -2.50301893e-01,\n",
       "         -1.00000000e+07, -4.28470043e-02, -1.00000000e+07,\n",
       "         -1.00000000e+07, -5.26189322e-01, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -3.56642088e-02,\n",
       "         -1.00000000e+07,  1.98801124e-03, -2.38277700e-01,\n",
       "         -4.16431274e-01, -2.01780056e-01,  6.86194816e-02,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07],\n",
       "        [-1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "          8.39074873e-02, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07,  5.00282191e-02,  5.92402302e-02,\n",
       "         -1.82666708e-01, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -3.16568492e-01, -1.00000000e+07,  4.71546660e-02,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -2.66276176e-02, -1.00000000e+07,\n",
       "         -1.00000000e+07,  2.09184647e-01, -3.21887653e-01,\n",
       "         -4.66779301e-01, -1.00000000e+07, -1.00000000e+07,\n",
       "         -3.11322654e-01,  9.35646975e-02, -4.44587841e-01,\n",
       "         -1.00000000e+07, -1.76717349e-01, -1.00000000e+07,\n",
       "         -1.00000000e+07, -3.67934038e-01, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -2.52297348e-01,\n",
       "         -1.00000000e+07, -2.24271972e-01, -1.45129800e-01,\n",
       "         -5.36174130e-01, -3.82855241e-01, -3.85640349e-02,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07],\n",
       "        [-1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -3.21350773e-01, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07,  3.38425363e-02,  3.41664528e-01,\n",
       "          1.12622333e-01, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -3.74275808e-01, -1.00000000e+07, -3.34584753e-01,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07,  2.59374025e-01, -1.00000000e+07,\n",
       "         -1.00000000e+07, -7.34795568e-02, -4.18033894e-02,\n",
       "          6.62699015e-01, -1.00000000e+07, -1.00000000e+07,\n",
       "         -5.87247532e-02,  2.68568636e-01, -5.62757590e-01,\n",
       "         -1.00000000e+07, -2.96791450e-01, -1.00000000e+07,\n",
       "         -1.00000000e+07, -5.04710686e-01, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07,  3.53592779e-01,\n",
       "         -1.00000000e+07,  1.39209175e-01,  1.12821644e-01,\n",
       "         -4.48041464e-01, -3.36489568e-01, -2.57617200e-01,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07, -1.00000000e+07,\n",
       "         -1.00000000e+07, -1.00000000e+07]]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rdry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SWC_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/aoes/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2888\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2889\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SWC_1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-4cbd0993e7e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlacc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSM_siteA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSM_siteA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SWC_F_MDS_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlacc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlacc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSM_siteA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SWC_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0msm_sort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSM_siteA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SWC_F_MDS_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aoes/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aoes/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SWC_1'"
     ]
    }
   ],
   "source": [
    "                Tmin_max_siteA_ano = Tmin_max_siteA.groupby(Tmin_max_siteA.index.month).transform(lambda g: g - g.mean())\n",
    "                Tmin_max_siteA_cli = Tmin_max_siteA.groupby(Tmin_max_siteA.index.month).transform(lambda g:  g.mean())\n",
    "                a=Tmin_max_siteA_cli.groupby(Tmin_max_siteA_cli.index.month)['max'].agg(['max']).to_numpy()\n",
    "                x = np.where(a == a.max())[0]+1\n",
    "                um=[x[0]-1,x[0],x[0]+1]\n",
    "                if x[0]>11:\n",
    "                    um=[11,12,1]\n",
    "                if x[0]<2:    \n",
    "                    um=[12,1,2]\n",
    "                for i in range(0,3):\n",
    "                    a = Tmin_max_siteA.index.month==um[i]    \n",
    "\n",
    "                    guess_dry_slope, guess_wet_slope = -50.0, -25.0\n",
    "\n",
    "                    lacc=SM_siteA[a].groupby(SM_siteA[a].index.year)['SWC_F_MDS_1'].apply(lambda x: x.autocorr(lag=1))\n",
    "                    tau = -1/np.log(np.sqrt(np.sum(lacc*np.abs(lacc))/40))\n",
    "                    dof=np.rint(float(len(SM_siteA[a]['SWC_1'])) / (tau + 1))\n",
    "\n",
    "                    sm_sort=SM_siteA[a]['SWC_F_MDS_1'].to_numpy()\n",
    "                    tx_sort=H_siteA[a]['H_F_MDS'].to_numpy()\n",
    "\n",
    "                    p , e = optimize.curve_fit(piecewise_linear, sm_sort, tx_sort, p0=[np.median(sm_sort),np.median(tx_sort),guess_dry_slope,guess_wet_slope], bounds=([np.min(sm_sort),np.min(tx_sort),-np.inf,-np.inf], [np.max(sm_sort),np.max(tx_sort),np.inf,np.inf]))\n",
    "                    wet_pts = sum(i > p[0] for i in sm_sort) \n",
    "                    dry_pts = sum(i <= p[0] for i in sm_sort) \n",
    "                    perr = np.sqrt(np.diag(e))\n",
    "                    vest = math.sqrt((tau+1)*(perr[2]*perr[2]/dry_pts+perr[3]*perr[3]/wet_pts)) # Adjust DOFs by tau, calculate z & p values for signif slope change\n",
    "                    z = abs(p[2]-p[3])/vest\n",
    "                    pval = st.norm.sf(abs(z))            \n",
    "                    dry_corr, dry_corp = st.pearsonr(sm_sort[:dry_pts],tx_sort[:dry_pts])\n",
    "                    wet_corr, wet_corp = st.pearsonr(sm_sort[-wet_pts:],tx_sort[-wet_pts:])\n",
    "\n",
    "\n",
    "\n",
    "                    Rdry[0,i,listn]=dry_corr\n",
    "                    Rwet[0,i,listn]=wet_corr\n",
    "                    SlopeSig[0,i,listn]=pval\n",
    "                    SMbk[0,i,listn]=p[0]\n",
    "                    Tbk[0,i,listn]=p[1]\n",
    "                    Slopedry[0,i,listn]=p[2]\n",
    "                    Slopewet[0,i,listn]=p[3]\n",
    "                    SMbk_pt[0,i,listn]=np.percentile(sm_sort,p[0]) \n",
    "                    nsize[0,i,listn]=np.size(sm_sort)\n",
    "                    iniyear[0,i,listn]=SM_siteA[a].index.year[1]\n",
    "                    endyear[0,i,listn]=SM_siteA[a].index.year[-1]\n",
    "                    usemonth[0,i,listn]=um[i] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SM_siteA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'SWC' in data_siteA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aoes)",
   "language": "python",
   "name": "aoes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
